<!DOCTYPE html>
<html>
<head>
    <title>Silent Vision Assistant</title>
    <style>
        body {
            background: #000;
            color: #0f0;
            font-family: 'Courier New', monospace;
            margin: 0;
            padding: 20px;
        }
        #container {
            display: grid;
            grid-template-columns: 1fr 300px;
            gap: 20px;
            height: 90vh;
        }
        #camera-box {
            border: 2px solid #0ff;
            position: relative;
        }
        #console {
            border: 2px solid #f0f;
            padding: 15px;
            overflow-y: scroll;
        }
        .user-msg { color: #0ff; }
        .sys-msg { color: #0f0; }
        .alert { color: #ff0; }
    </style>
</head>
<body>
    <h1>TEXT-ONLY VISION ASSISTANT</h1>
    <div id="container">
        <div id="camera-box">
            <video id="video" width="640" height="480" autoplay muted></video>
            <canvas id="sensor-overlay"></canvas>
        </div>
        <div id="console"></div>
    </div>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/holistic/holistic.js"></script>

<script>
const consoleOutput = document.getElementById('console');
let lastDetection = {
    face: null,
    pose: null,
    hands: null
};

// Initialize MediaPipe Holistic
const holistic = new Holistic({
    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/holistic/${file}`
});

holistic.setOptions({
    modelComplexity: 1,
    smoothLandmarks: true,
    enableSegmentation: false,
    refineFaceLandmarks: true
});

// Camera setup
const video = document.getElementById('video');
const camera = new Camera(video, {
    onFrame: async () => {
        await holistic.send({image: video});
    },
    width: 640,
    height: 480
});

holistic.onResults((results) => {
    lastDetection = {
        face: results.faceLandmarks,
        pose: results.poseLandmarks,
        hands: results.handedness
    };
    updateDisplay();
});

// Text analysis
function analyzeText(input) {
    const responses = [
        "Processing visual data...",
        "Tracking "+ (lastDetection.face ? "1 face" : "no faces"),
        "Posture analysis: "+ (lastDetection.pose ? "neutral" : "unknown"),
        "Motion patterns: "+ (lastDetection.hands ? "hands detected" : "no hand activity")
    ];
    
    return responses[Math.floor(Math.random()*responses.length)];
}

// Display updates
function updateDisplay() {
    const logEntry = `SYSTEM: Tracking ${
        lastDetection.face ? 'face' : 'no face'
    } | ${
        lastDetection.pose ? 'body' : 'no body'
    } | ${
        lastDetection.hands ? lastDetection.hands.length+' hands' : 'no hands'
    }`;
    
    addToConsole(logEntry, 'sys-msg');
}

function addToConsole(text, className='sys-msg') {
    consoleOutput.innerHTML += `<div class="${className}">${text}</div>`;
    consoleOutput.scrollTop = consoleOutput.scrollHeight;
}

// Start systems
camera.start();
addToConsole("SYSTEM: Initializing sensors...", 'alert');

// Simulate user input
setInterval(() => {
    const fakeInput = "User presence detected";
    addToConsole(`USER: ${fakeInput}`, 'user-msg');
    const response = analyzeText(fakeInput);
    addToConsole(`AI: ${response}`, 'sys-msg');
}, 5000);
</script>
</body>
</html>
