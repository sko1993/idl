<!DOCTYPE html>
<html>
<head>
    <title>Futuristic Bot</title>
    <style>
        body {
            font-family: 'Courier New', monospace;
            background-color: #000;
            color: #0f0;
            text-align: center;
            padding: 20px;
        }
        #camera {
            width: 320px;
            height: 240px;
            border: 2px solid #0f0;
            margin: 10px auto;
        }
        #output {
            height: 100px;
            border: 1px solid #0f0;
            padding: 10px;
            margin: 10px auto;
            width: 80%;
            overflow-y: scroll;
        }
        button {
            background-color: #000;
            color: #0f0;
            border: 1px solid #0f0;
            padding: 10px 20px;
            margin: 5px;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <h1>FUTURISTIC BOT INTERFACE</h1>
    <div id="camera"></div>
    <div id="output">SYSTEM: Initializing...</div>
    <button id="startBtn">ACTIVATE</button>
    <button id="listenBtn">LISTEN</button>
    
    <script>
        // Futuristic responses
        const responses = [
            "Scan complete. Human detected.",
            "Vocal input processed.",
            "Motion sensors activated.",
            "System status: Nominal.",
            "Alert: Energy signature detected.",
            "Command acknowledged."
        ];

        const output = document.getElementById('output');
        const startBtn = document.getElementById('startBtn');
        const listenBtn = document.getElementById('listenBtn');
        let cameraActive = false;
        let video;

        // Camera setup
        startBtn.addEventListener('click', async () => {
            try {
                video = document.createElement('video');
                document.getElementById('camera').appendChild(video);
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                video.play();
                cameraActive = true;
                logMessage("SYSTEM: Visual sensors online");
            } catch (err) {
                logMessage(`ERROR: ${err.message}`);
            }
        });

        // Voice recognition
        listenBtn.addEventListener('click', () => {
            if (!('webkitSpeechRecognition' in window)) {
                logMessage("ERROR: Voice recognition not supported");
                return;
            }

            const recognition = new webkitSpeechRecognition();
            recognition.lang = 'en-US';
            
            recognition.onstart = () => {
                logMessage("SYSTEM: Listening...");
            };
            
            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                logMessage(`YOU: ${transcript}`);
                const response = responses[Math.floor(Math.random() * responses.length)];
                speak(response);
            };
            
            recognition.onerror = (event) => {
                logMessage(`ERROR: ${event.error}`);
            };
            
            recognition.start();
        });

        // Helper functions
        function logMessage(msg) {
            output.innerHTML += `<div>${msg}</div>`;
            output.scrollTop = output.scrollHeight;
        }

        function speak(text) {
            logMessage(`BOT: ${text}`);
            const utterance = new SpeechSynthesisUtterance(text);
            speechSynthesis.speak(utterance);
        }
    </script>
</body>
</html>
